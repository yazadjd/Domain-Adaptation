# -*- coding: utf-8 -*-
"""OneHotEncoding of SML_Project2_Mixed.ipynb

Automatically generated by Colaboratory.

This notebook contains code relevant to running all baselines using one hot encoded features for target domain = MIXED for Task 1.1 of SML Project 2 - Sem 1, 2020.
"""

import pandas as pd
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
from statistics import mean
import numpy as np
from sklearn import datasets, linear_model
from sklearn import metrics
from sklearn.neural_network import MLPRegressor
from sklearn.metrics import mean_squared_error
from sklearn.metrics import mean_absolute_error
from math import sqrt
from operator import itemgetter
from scipy import interpolate

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/drive/My Drive/SML_Proj2

male = pd.read_csv("MALE.csv")
female = pd.read_csv("FEMALE.csv")
mixed = pd.read_csv("MIXED.csv")

male_features  = male[['Year',	'FSM',	'VR1 Band',	'VR Band of Student',	'Ethnic group of student',	'School denomination']]
male_scores = male [['Exam Score']]

to_encode = ['Year', 'VR Band of Student', 'Ethnic group of student', 'School denomination']

male_features = pd.get_dummies(male_features, prefix_sep = "__", columns = to_encode)

columns = list(male_features)
print(len(columns))

#Splitting data for male
X_train, male_X_test, y_train, male_Y_test = train_test_split(male_features, male_scores, test_size = 0.2, random_state = 42)
male_X_train, male_X_val, male_Y_train, male_Y_val = train_test_split(X_train, y_train, test_size = 100, random_state = 42)

#Checking distribution using mean of each partition
print(mean(male_Y_test['Exam Score']))
print(mean(male_Y_train['Exam Score']))
print(mean(male_Y_val['Exam Score']))

female_features  = female[['Year',	'FSM',	'VR1 Band',	'VR Band of Student',	'Ethnic group of student',	'School denomination']]
female_scores = female [['Exam Score']]

female_features = pd.get_dummies(female_features, prefix_sep = "__", columns = to_encode)

columns = list(female_features)
print(columns)

#Splitting data for female

X_train, female_X_test, y_train, female_Y_test = train_test_split(female_features, female_scores, test_size = 0.2, random_state = 42)
female_X_train, female_X_val, female_Y_train, female_Y_val = train_test_split(X_train, y_train, test_size = 100, random_state = 42)

#Checking distribution using mean of each partition
print(mean(female_Y_test['Exam Score']))
print(mean(female_Y_train['Exam Score']))
print(mean(female_Y_val['Exam Score']))

mixed.drop(mixed[mixed['VR Band of Student'] == 0].index, inplace = True) 
mixed_features  = mixed[['Year',	'FSM',	'VR1 Band',	'VR Band of Student',	'Ethnic group of student',	'School denomination']]
mixed_scores = mixed[['Exam Score']]

mixed_features = pd.get_dummies(mixed_features, prefix_sep = "__", columns = to_encode)

columns = list(mixed_features)
print(columns)

#Splitting data for mixed

X_train, mixed_X_test, y_train, mixed_Y_test = train_test_split(mixed_features, mixed_scores, test_size = 0.2, random_state = 42)
mixed_X_train, mixed_X_val, mixed_Y_train, mixed_Y_val = train_test_split(X_train, y_train, test_size = 100, random_state = 42)

#Checking distribution using mean of each partition
print(mean(mixed_Y_test['Exam Score']))
print(mean(mixed_Y_train['Exam Score']))
print(mean(mixed_Y_val['Exam Score']))

#Reproducible Sampling function to get 100 instances without replacement
def sample(df):
  return df.sample(n = 100, replace = False, random_state = 42)

"""TARGET DOMAIN = MIXED

SRCONLY
"""

x_train = pd.concat([female_X_train, male_X_train])
y_train = pd.concat([female_Y_train, male_Y_train])

lin_reg(x_train, y_train, mixed_X_val, mixed_Y_val)
lin_reg(x_train, y_train, mixed_X_test, mixed_Y_test)

# random_state = 42, max_iter = 1000, activation = 'relu', solver = 'adam', hidden_layer_sizes=h, learning_rate='constant', learning_rate_init= 0.001)
MLP_Reg(x_train, y_train, mixed_X_val, mixed_Y_val, 104)
MLP_Reg(x_train, y_train, mixed_X_test, mixed_Y_test, 104)

"""TGTONLY"""

x_train = sample(mixed_X_train)
y_train = sample(mixed_Y_train)

lin_reg(x_train, y_train, mixed_X_val, mixed_Y_val)
lin_reg(x_train, y_train, mixed_X_test, mixed_Y_test)

#MLPRegressor(random_state = 42, max_iter = 1000, activation = 'relu', solver = 'adam', hidden_layer_sizes=h, learning_rate='constant', learning_rate_init= 0.001)
MLP_Reg(x_train, y_train, mixed_X_val, mixed_Y_val, 12)
MLP_Reg(x_train, y_train, mixed_X_test, mixed_Y_test, 12)

"""ALL"""

x_train = pd.concat([sample(mixed_X_train), female_X_train, male_X_train])
y_train = pd.concat([sample(mixed_Y_train), female_Y_train, male_Y_train])

lin_reg(x_train, y_train, male_X_val, male_Y_val)
lin_reg(x_train, y_train, male_X_test, male_Y_test)

#MLPRegressor(random_state = 42, max_iter = 1000, activation = 'relu', solver = 'adam', hidden_layer_sizes=h, learning_rate='constant', learning_rate_init= 0.001)
MLP_Reg(x_train, y_train, male_X_val, male_Y_val, 13)
MLP_Reg(x_train, y_train, male_X_test, male_Y_test, 13)

"""WEIGHTED"""

print(male_X_train.shape)
print(female_X_train.shape)

#CHECKING
x_train = pd.concat([sample(mixed_X_train)]*62, ignore_index=True)
x_train = pd.concat([x_train, x_train.head(46), female_X_train, male_X_train], ignore_index = True)
y_train = pd.concat([sample(mixed_Y_train)]*62, ignore_index=True)
y_train = pd.concat([y_train, y_train.head(46), female_Y_train, male_Y_train], ignore_index = True)

lin_reg(x_train, y_train, mixed_X_val, mixed_Y_val)
lin_reg(x_train, y_train, mixed_X_test, mixed_Y_test)

# MLPRegressor(random_state = 42, max_iter = 10000, activation = 'relu', solver = 'adam', hidden_layer_sizes=h, learning_rate='constant', learning_rate_init= 0.001)
MLP_Reg(x_train, y_train, mixed_X_val, mixed_Y_val, 12)
MLP_Reg(x_train, y_train, mixed_X_test, mixed_Y_test, 12)

"""PRED"""

x_train = pd.concat([female_X_train, male_X_train])
y_train = pd.concat([female_Y_train, male_Y_train])

predictions = lin_reg(x_train, y_train, mixed_features, mixed_scores)
augmented_mixed_features = mixed_features.assign(src_preds = predictions)
X_train, mixed_X_test, y_train, mixed_Y_test = train_test_split(augmented_mixed_features, mixed_scores, test_size = 0.2, random_state = 42)
mixed_X_train, mixed_X_val, mixed_Y_train, mixed_Y_val = train_test_split(X_train, y_train, test_size = 100, random_state = 42)
x_train = sample(mixed_X_train)
y_train = sample(mixed_Y_train)

lin_reg(x_train, y_train, mixed_X_val, mixed_Y_val)
lin_reg(x_train, y_train, mixed_X_test, mixed_Y_test)

#MLPRegressor(random_state = 42, max_iter = 10000, activation = 'relu', solver = 'adam', hidden_layer_sizes=h, learning_rate='constant', learning_rate_init= 0.001)
predictions = MLP_Reg(x_train, y_train, mixed_features, mixed_scores, 104)
augmented_mixed_features = mixed_features.assign(src_preds = predictions)
X_train, mixed_X_test, y_train, mixed_Y_test = train_test_split(augmented_mixed_features, mixed_scores, test_size = 0.2, random_state = 42)
mixed_X_train, mixed_X_val, mixed_Y_train, mixed_Y_val = train_test_split(X_train, y_train, test_size = 100, random_state = 42)
x_train = sample(mixed_X_train)
y_train = sample(mixed_Y_train)

mixed_X_train.head()

# MLPRegressor(random_state = 42, max_iter = 10000, activation = 'relu', solver = 'adam', hidden_layer_sizes=h, learning_rate='constant', learning_rate_init= 0.001)
MLP_Reg(x_train, y_train, mixed_X_val, mixed_Y_val, 6)
MLP_Reg(x_train, y_train, mixed_X_test, mixed_Y_test, 6)

def lin_reg(x_train, y_train, x_val, y_val):
  regr = linear_model.LinearRegression()
  regr.fit(x_train, y_train)
  lin_pred = regr.predict(x_val)
  print('Mean Absolute Error:', metrics.mean_absolute_error(y_val, lin_pred))
  print('Mean Squared Error:', metrics.mean_squared_error(y_val, lin_pred))
  print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_val, lin_pred)))
  return lin_pred

all = []
for n in range(1,200):
  all.append((MLP_Reg(x_train, y_train, mixed_X_val, mixed_Y_val, n), n))
print(min(all, key = itemgetter(0))[1])

def MLP_Reg(x_train, y_train, x_val, y_val, h):
  regr = MLPRegressor(random_state = 42, max_iter = 1000, activation = 'relu', solver = 'adam', hidden_layer_sizes=h, learning_rate='constant', learning_rate_init= 0.001)
  regr.fit(x_train, y_train)
  MLP_pred = regr.predict(x_val)
  print('Mean Absolute Error:', metrics.mean_absolute_error(y_val, MLP_pred))
  print('Mean Squared Error:', metrics.mean_squared_error(y_val, MLP_pred), 'h = ', h)
  print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_val, MLP_pred)))
  #return metrics.mean_squared_error(y_val, MLP_pred)
  return MLP_pred

"""LININT"""

x_train = pd.concat([female_X_train, male_X_train])
y_train = pd.concat([female_Y_train, male_Y_train])
# MLPRegressor(random_state = 42, max_iter = 10000, activation = 'relu', solver = 'adam', hidden_layer_sizes=h)
srconly_preds = MLP_Reg(x_train, y_train, mixed_X_val, mixed_Y_val, 104)
srconly_preds_test = MLP_Reg(x_train, y_train, mixed_X_test, mixed_Y_test, 104)

x_train = sample(mixed_X_train)
y_train = sample(mixed_Y_train)
#MLPRegressor(random_state = 42, max_iter = 1000, activation = 'relu', solver = 'adam', hidden_layer_sizes=h, learning_rate='constant', learning_rate_init= 0.001)
tgtonly_preds = MLP_Reg(x_train, y_train, mixed_X_val, mixed_Y_val, 12)
tgtonly_preds_test = MLP_Reg(x_train, y_train, mixed_X_test, mixed_Y_test, 12)
data = {'y1' : srconly_preds, 'y2 - y1' : np.absolute(tgtonly_preds - srconly_preds)}
x_train = pd.DataFrame(data)
y_train = mixed_Y_val
regr = linear_model.LinearRegression(fit_intercept = False) 
regr.fit(x_train, y_train) #Coeff of y1 is approx 1
print(regr.coef_)
data = {'y1' : srconly_preds_test, 'y2 - y1' : np.absolute(tgtonly_preds_test - srconly_preds_test)}
lin_pred = regr.predict(pd.DataFrame(data))
print(metrics.mean_squared_error(mixed_Y_test, lin_pred))

x_train = pd.concat([female_X_train, male_X_train])
y_train = pd.concat([female_Y_train, male_Y_train])
srconly_preds = lin_reg(x_train, y_train, mixed_X_val, mixed_Y_val)
srconly_preds_test = lin_reg(x_train, y_train, mixed_X_test, mixed_Y_test)

x_train = sample(mixed_X_train)
y_train = sample(mixed_Y_train)

tgtonly_preds = lin_reg(x_train, y_train, mixed_X_val, mixed_Y_val)
tgtonly_preds_test = lin_reg(x_train, y_train, mixed_X_test, mixed_Y_test)
lst2 = np.absolute(tgtonly_preds - srconly_preds)
x_train = pd.DataFrame(list(zip(srconly_preds, lst2)), columns = ['y1', 'y2 - y1']) 
y_train = mixed_Y_val
regr = linear_model.LinearRegression(fit_intercept=False)
regr.fit(x_train, y_train) #Coeff of y1 is approx 1
print(regr.coef_)
#data = {'y1' : srconly_preds_test, 'y2 - y1' : np.absolute(tgtonly_preds_test - srconly_preds_test)}
lin_pred = regr.predict(pd.DataFrame(pd.DataFrame(list(zip(srconly_preds_test, np.absolute(tgtonly_preds_test - srconly_preds_test))), columns = ['y1', 'y2 - y1'])))
print(metrics.mean_squared_error(mixed_Y_test, lin_pred))

